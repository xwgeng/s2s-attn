## Sequece-to-Sequence Model with attention

Sequence-to-sequence model with attention implemented by [Torch](http://torch.ch).
The encoder can be bidirectional recurrent neural network(LSTM | GRU | RNN). Additionally, the convolutional attentive encoder([Rush et al. 2015](https://www.aclweb.org/anthology/D/D15/D15-1044.pdf)) is also implemented inspired by [Bahdanau et al.(2015)](https://arxiv.org/pdf/1409.0473v7.pdf). 

### Dependencies

#### Lua
* Moses
* Penlight

#### Torch
The model is implemented by [torch](http://torch.ch). It requires the following packages:
* torch7
* nn
* nngraph
* cutorch
* cunn
* paths

### Quikstart



